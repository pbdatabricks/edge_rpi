<!DOCTYPE html><html><head><meta charset="utf-8"><title>Pytorch Installation on Raspberry Pi 4.md</title><style></style></head><body id="preview">
<h1 class="code-line" data-line-start=0 data-line-end=1><a id="Pytorch_Installation_on_Raspberry_Pi_4_0"></a>Pytorch Installation on Raspberry Pi 4</h1>
<p class="has-line-data" data-line-start="2" data-line-end="3">Environment Configuration:</p>
<ul>
<li class="has-line-data" data-line-start="4" data-line-end="11">
<p class="has-line-data" data-line-start="4" data-line-end="6"><a href="https://downloads.raspberrypi.org/raspios_lite_armhf/images/raspios_lite_armhf-2021-05-28/2021-05-07-raspios-buster-armhf-lite.zip">Raspbian GNU/Linux 10 (buster)</a><br>
– You can verify by</p>
<pre><code class="has-line-data" data-line-start="7" data-line-end="9" class="language-sh">cat /etc/os-release
</code></pre>
<p class="has-line-data" data-line-start="9" data-line-end="10">– If not installed, I recommend downloading the <a href="https://downloads.raspberrypi.org/raspios_lite_armhf/images/raspios_lite_armhf-2021-05-28/2021-05-07-raspios-buster-armhf-lite.zip">lite version</a>, and use the <a href="https://downloads.raspberrypi.org/imager/imager_latest.dmg">Raspberry Pi Imager</a> to burn the image on the SD Card by selecting the ‘Choose OS’ --&gt; ‘Use Custom’</p>
</li>
<li class="has-line-data" data-line-start="11" data-line-end="16">
<p class="has-line-data" data-line-start="11" data-line-end="12">ARMv7 Processor rev 3 (v7l)</p>
<pre><code class="has-line-data" data-line-start="13" data-line-end="15" class="language-sh">cat /proc/cpuinfo
</code></pre>
</li>
</ul>
<h2 class="code-line" data-line-start=16 data-line-end=17><a id="Installing_Torch_from_ljk53httpsgithubcomljk53pytorchrpiblobmastertorch170a0cp37cp37mlinux_armv7lwhl_16"></a>Installing Torch from <a href="https://github.com/ljk53/pytorch-rpi/blob/master/torch-1.7.0a0-cp37-cp37m-linux_armv7l.whl">ljk53</a></h2>
<ul>
<li class="has-line-data" data-line-start="17" data-line-end="22">Update &amp; Upgrade<pre><code class="has-line-data" data-line-start="19" data-line-end="22" class="language-sh">sudo apt-get update
sudo apt-get upgrade
</code></pre>
</li>
<li class="has-line-data" data-line-start="22" data-line-end="29">Install Dependencies<pre><code class="has-line-data" data-line-start="24" data-line-end="29" class="language-sh">sudo apt-get install ninja-build git cmake
sudo apt-get install libopenmpi-dev libomp-dev ccache
sudo apt-get install libopenblas-dev libblas-dev libeigen3-dev libopenblas-base libatlas-base-dev
sudo -H pip3 install -U --user wheel mock pillow
</code></pre>
</li>
<li class="has-line-data" data-line-start="29" data-line-end="33">Upgrade setuptools<pre><code class="has-line-data" data-line-start="31" data-line-end="33" class="language-sh">sudo -H pip3 install -U setuptools
</code></pre>
</li>
<li class="has-line-data" data-line-start="33" data-line-end="39">Download the pytorch wheel<pre><code class="has-line-data" data-line-start="35" data-line-end="39" class="language-sh">mkdir &lt;DIRECTORY_OF_CHOICE&gt;
<span class="hljs-built_in">cd</span> &lt;DIR_PATH&gt;
wget https://github.com/ljk53/pytorch-rpi/blob/master/torch-<span class="hljs-number">1.7</span>.<span class="hljs-number">0</span>a0-cp37-cp37m-linux_armv7l.whl
</code></pre>
</li>
<li class="has-line-data" data-line-start="39" data-line-end="43">Install wheel<pre><code class="has-line-data" data-line-start="41" data-line-end="43" class="language-sh">pip3 install torch-<span class="hljs-number">1.7</span>.<span class="hljs-number">0</span>a0-cp37-cp37m-linux_armv7l.whl 
</code></pre>
</li>
<li class="has-line-data" data-line-start="43" data-line-end="50">Quick test to make sure it works<pre><code class="has-line-data" data-line-start="45" data-line-end="49" class="language-sh">python3
&gt;&gt;&gt; import torch
&gt;&gt;&gt; <span class="hljs-built_in">print</span>(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>))
</code></pre>
</li>
</ul>
<h2 class="code-line" data-line-start=50 data-line-end=51><a id="Install_torchvision_from_nmilosevhttpsgithubcomnmilosevpytorcharmbuildsblobmastertorchvision040a02Bd31eafacp37cp37mlinux_armv7lwhl_50"></a>Install torchvision from <a href="https://github.com/nmilosev/pytorch-arm-builds/blob/master/torchvision-0.4.0a0%2Bd31eafa-cp37-cp37m-linux_armv7l.whl">nmilosev</a></h2>
<ul>
<li class="has-line-data" data-line-start="51" data-line-end="57">Download &amp; Install wheel<pre><code class="has-line-data" data-line-start="53" data-line-end="57" class="language-sh"><span class="hljs-built_in">cd</span> &lt;DIR_PATH&gt;
wget https://github.com/nmilosev/pytorch-arm-builds/blob/master/torchvision-<span class="hljs-number">0.4</span>.<span class="hljs-number">0</span>a0%<span class="hljs-number">2</span>Bd31eafa-cp37-cp37m-linux_armv7l.whl
pip3 install torchvision-<span class="hljs-number">0.4</span>.<span class="hljs-number">0</span>a0+d31eafa-cp37-cp37m-linux_armv7l.whl 
</code></pre>
</li>
<li class="has-line-data" data-line-start="57" data-line-end="62">Quick test<pre><code class="has-line-data" data-line-start="59" data-line-end="62" class="language-sh">python3
&gt;&gt;&gt; import torchvision
</code></pre>
</li>
<li class="has-line-data" data-line-start="62" data-line-end="68">If it fails, you may install additional libs<pre><code class="has-line-data" data-line-start="64" data-line-end="67" class="language-sh">sudo apt-get install libjpeg-dev zlib1g-dev libpython3-dev
sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev
</code></pre>
</li>
</ul>
<h2 class="code-line" data-line-start=68 data-line-end=69><a id="Running_Flask_68"></a>Running Flask</h2>
<ul>
<li class="has-line-data" data-line-start="69" data-line-end="125">Install requirements.txt (this file contains libs for both camera capture and flask)<pre><code class="has-line-data" data-line-start="71" data-line-end="122" class="language-sh">alembic==<span class="hljs-number">1.4</span>.<span class="hljs-number">1</span>
boto3==<span class="hljs-number">1.17</span>.<span class="hljs-number">110</span>
botocore==<span class="hljs-number">1.20</span>.<span class="hljs-number">110</span>
certifi==<span class="hljs-number">2021.5</span>.<span class="hljs-number">30</span>
charset-normalizer==<span class="hljs-number">2.0</span>.<span class="hljs-number">4</span>
click==<span class="hljs-number">8.0</span>.<span class="hljs-number">1</span>
cloudpickle==<span class="hljs-number">1.6</span>.<span class="hljs-number">0</span>
databricks-cli==<span class="hljs-number">0.15</span>.<span class="hljs-number">0</span>
dataclasses==<span class="hljs-number">0.6</span>
docker==<span class="hljs-number">5.0</span>.<span class="hljs-number">0</span>
entrypoints==<span class="hljs-number">0.3</span>
Flask==<span class="hljs-number">2.0</span>.<span class="hljs-number">1</span>
future==<span class="hljs-number">0.18</span>.<span class="hljs-number">2</span>
gitdb==<span class="hljs-number">4.0</span>.<span class="hljs-number">7</span>
GitPython==<span class="hljs-number">3.1</span>.<span class="hljs-number">18</span>
gunicorn==<span class="hljs-number">20.1</span>.<span class="hljs-number">0</span>
idna==<span class="hljs-number">3.2</span>
importlib-metadata==<span class="hljs-number">4.6</span>.<span class="hljs-number">4</span>
itsdangerous==<span class="hljs-number">2.0</span>.<span class="hljs-number">1</span>
Jinja2==<span class="hljs-number">3.0</span>.<span class="hljs-number">1</span>
jmespath==<span class="hljs-number">0.10</span>.<span class="hljs-number">0</span>
Mako==<span class="hljs-number">1.1</span>.<span class="hljs-number">5</span>
MarkupSafe==<span class="hljs-number">2.0</span>.<span class="hljs-number">1</span>
mlflow==<span class="hljs-number">1.20</span>.<span class="hljs-number">1</span>
numpy==<span class="hljs-number">1.21</span>.<span class="hljs-number">2</span>
packaging==<span class="hljs-number">21.0</span>
pandas==<span class="hljs-number">1.1</span>.<span class="hljs-number">5</span>
picamera==<span class="hljs-number">1.13</span>
Pillow==<span class="hljs-number">8.3</span>.<span class="hljs-number">1</span>
prometheus-client==<span class="hljs-number">0.11</span>.<span class="hljs-number">0</span>
prometheus-flask-exporter==<span class="hljs-number">0.18</span>.<span class="hljs-number">2</span>
protobuf==<span class="hljs-number">3.17</span>.<span class="hljs-number">3</span>
pyparsing==<span class="hljs-number">2.4</span>.<span class="hljs-number">7</span>
python-dateutil==<span class="hljs-number">2.8</span>.<span class="hljs-number">1</span>
python-editor==<span class="hljs-number">1.0</span>.<span class="hljs-number">4</span>
pytz==<span class="hljs-number">2021.1</span>
PyYAML==<span class="hljs-number">5.4</span>.<span class="hljs-number">1</span>
querystring-parser==<span class="hljs-number">1.2</span>.<span class="hljs-number">4</span>
requests==<span class="hljs-number">2.26</span>.<span class="hljs-number">0</span>
s3transfer==<span class="hljs-number">0.4</span>.<span class="hljs-number">2</span>
six==<span class="hljs-number">1.16</span>.<span class="hljs-number">0</span>
smmap==<span class="hljs-number">4.0</span>.<span class="hljs-number">0</span>
SQLAlchemy==<span class="hljs-number">1.4</span>.<span class="hljs-number">23</span>
sqlparse==<span class="hljs-number">0.4</span>.<span class="hljs-number">1</span>
tabulate==<span class="hljs-number">0.8</span>.<span class="hljs-number">9</span>
typing-extensions==<span class="hljs-number">3.10</span>.<span class="hljs-number">0.0</span>
urllib3==<span class="hljs-number">1.26</span>.<span class="hljs-number">6</span>
websocket-client==<span class="hljs-number">1.2</span>.<span class="hljs-number">1</span>
Werkzeug==<span class="hljs-number">2.0</span>.<span class="hljs-number">1</span>
zipp==<span class="hljs-number">3.5</span>.<span class="hljs-number">0</span>
</code></pre>
<pre><code class="has-line-data" data-line-start="123" data-line-end="125" class="language-sh">pip3 install -r requirements.txt
</code></pre>
</li>
<li class="has-line-data" data-line-start="125" data-line-end="232">Copying the flask_server_api.py file<pre><code class="has-line-data" data-line-start="127" data-line-end="232" class="language-sh">import base64
import io
import tarfile

import requests
from flask import Flask, request, jsonify
import torch
import mlflow
import numpy
from torchvision import datasets, models, transforms
from PIL import Image, ImageDraw
from picamera import PiCamera
from time import sleep
import datetime as dt
import sys
import subprocess
import os
import json
from torch.hub import load_state_dict_from_url
from torchvision.models import mobilenet_v2 as mobilenetv2

app = Flask(__name__)
@app.route(<span class="hljs-string">'/'</span>, methods=[<span class="hljs-string">'GET'</span>])
def alive():
    timestamp = dt.datetime.now()
    <span class="hljs-built_in">return</span> jsonify({<span class="hljs-string">"response"</span>:<span class="hljs-string">"API is alive"</span>, <span class="hljs-string">"status"</span>:<span class="hljs-string">"200"</span>, <span class="hljs-string">"url"</span>:<span class="hljs-string">"frostydew1905.cotunnel.com"</span>, <span class="hljs-string">"timestamp"</span>: timestamp})

@app.route(<span class="hljs-string">'/api/send_url/'</span>, methods=[<span class="hljs-string">'GET'</span>, <span class="hljs-string">'POST'</span>])
def get_url():
    content = request.json
    model = content[<span class="hljs-string">"model"</span>]
    version = content[<span class="hljs-string">"version"</span>]
    url = content[<span class="hljs-string">"url"</span>]
    status = <span class="hljs-string">"SUCCESS"</span>
    response = requests.get(url, stream=True)
    target_path = <span class="hljs-string">'/home/pi/compressed/model.tar.gz'</span>
    timestamp = dt.datetime.now()
    <span class="hljs-keyword">if</span> response.status_code == <span class="hljs-number">200</span>:
        with open(target_path, <span class="hljs-string">'wb'</span>) as f:
            f.write(response.raw.read())
    <span class="hljs-built_in">return</span> jsonify({<span class="hljs-string">"url"</span>: url, <span class="hljs-string">"model"</span>: model, <span class="hljs-string">"version"</span>: version, <span class="hljs-string">"status"</span>: status, <span class="hljs-string">"timestamp"</span>: timestamp})

@app.route(<span class="hljs-string">'/api/artifacts/'</span>, methods=[<span class="hljs-string">'GET'</span>, <span class="hljs-string">'POST'</span>])
def download_artifacts():
    content = request.json
    model = content[<span class="hljs-string">"model"</span>]
    version = content[<span class="hljs-string">"version"</span>]
    data = content[<span class="hljs-string">"data"</span>]
    string_to_b64 = data.encode(<span class="hljs-string">'utf-8'</span>)
    b64_to_bytes = base64.b64decode(string_to_b64)
    file_like_object = io.BytesIO(b64_to_bytes)
    tar = tarfile.open(fileobj=file_like_object, mode=<span class="hljs-string">'r:gz'</span>)
    dest_path = <span class="hljs-string">'/home/pi/artifacts/'</span> + model + <span class="hljs-string">'_'</span> + version + <span class="hljs-string">'/'</span>
    tar.extractall(path=dest_path)
    timestamp = dt.datetime.now()
    <span class="hljs-built_in">return</span> jsonify({<span class="hljs-string">"model"</span>: model, <span class="hljs-string">"version"</span>: version, <span class="hljs-string">"status"</span>: <span class="hljs-string">"production"</span>, <span class="hljs-string">"dest_path"</span>: dest_path, <span class="hljs-string">"timestamp"</span>: timestamp})

@app.route(<span class="hljs-string">'/api/inference/'</span>, methods=[<span class="hljs-string">'GET'</span>])
def infer():
    model_path = <span class="hljs-string">'/home/pi/artifacts/MobileNetV3_100/MobileNetV3/data/model.pth'</span>
    labels = json.dumps({<span class="hljs-string">"0"</span>: <span class="hljs-string">"empty"</span>, <span class="hljs-string">"1"</span>: <span class="hljs-string">"box"</span>})
    CURRENT_DATE = dt.datetime.now().strftime(<span class="hljs-string">'%m-%d-%Y_%H:%M:%S'</span>)
    camera = PiCamera()
    camera.resolution = (<span class="hljs-number">600</span>, <span class="hljs-number">600</span>)
    camera.framerate = <span class="hljs-number">15</span>
    camera.start_preview()
    sleep(<span class="hljs-number">10</span>)

    image_filepath = <span class="hljs-string">'/home/pi/images/'</span> + CURRENT_DATE + <span class="hljs-string">'.jpg'</span>
    camera.capture(image_filepath)
    camera.stop_preview()
    camera.close()
    <span class="hljs-built_in">test</span>_image = image_filepath
    device = torch.device(<span class="hljs-string">"cuda:0"</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">"cpu"</span>)
    labels = json.loads(labels)
    data_transform = transforms.Compose([
        transforms.Resize((<span class="hljs-number">256</span>, <span class="hljs-number">256</span>)),
        transforms.CenterCrop(<span class="hljs-number">224</span>),
        transforms.ToTensor(),
        transforms.Normalize(mean=[<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], std=[<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>]),
    ])
    img = Image.open(<span class="hljs-built_in">test</span>_image)
    image = data_transform(img).unsqueeze(<span class="hljs-number">0</span>).to(device)
    model = torch.load(model_path, pickle_module=mlflow.pytorch.pickle_module, map_location=torch.device(<span class="hljs-string">'cpu'</span>))
    model.to(device)
    model.eval()
    out = model(image)
    <span class="hljs-comment"># print(out)</span>
    <span class="hljs-built_in">print</span>(out.argmax().item())
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"Predicted class is: {}"</span>.format(labels[str(out.argmax().item())]))
    prediction = labels[str(out.argmax().item())]
    timestamp = dt.datetime.now()
    d1 = ImageDraw.Draw(img)
    text = <span class="hljs-string">"Prediction: "</span> + prediction
    d1.text((<span class="hljs-number">28</span>, <span class="hljs-number">36</span>), text, fill=(<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>))
    buf = io.BytesIO()
    img.save(buf, <span class="hljs-string">'jpeg'</span>)
    buf.seek(<span class="hljs-number">0</span>)
    img_bytes = buf.read()
    buf.close()
    <span class="hljs-built_in">return</span> jsonify({<span class="hljs-string">"predicted"</span>: prediction, <span class="hljs-string">"timestamp"</span>: timestamp, <span class="hljs-string">"image"</span>: base64.b64encode(img_bytes).decode(<span class="hljs-string">'utf-8'</span>)})

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    app.run(host=<span class="hljs-string">'0.0.0.0'</span>, port=<span class="hljs-string">'8080'</span>, debug=True)
</code></pre>
</li>
<li class="has-line-data" data-line-start="232" data-line-end="246">Testing with Postman<br>
– Send a GET request to the raspberry pi local address (make sure to disconnect from VPN). You can locate it by:<br>
<code>sh arp-scan --localhost</code><br>
If successful, you should see the following after sending a GET request using &lt;RPI IP&gt;/:<br>
<code>sh { &quot;response&quot;: &quot;API is alive&quot;, &quot;status&quot;: &quot;200&quot;, &quot;timestamp&quot;: &quot;Mon, 04 Oct 2021 22:43:10 GMT&quot;, &quot;url&quot;: &quot;frostydew1905.cotunnel.com&quot; }</code></li>
<li class="has-line-data" data-line-start="246" data-line-end="786">Getting /api/inference endpoint to work<br>
– Create two folders<pre><code class="has-line-data" data-line-start="249" data-line-end="252" class="language-sh">mkdir /home/pi/artifacts
mkdir /home/pi/images
</code></pre>
– Verify if the pre-trained model is in the modules (it won’t likely be)<pre><code class="has-line-data" data-line-start="254" data-line-end="258" class="language-sh">python3
&gt;&gt;&gt; import torchvision
&gt;&gt;&gt; torchvision.__file__
</code></pre>
– Copy the filepath and replace <strong>init</strong>.py by models, so your path should look like:<pre><code class="has-line-data" data-line-start="260" data-line-end="262" class="language-sh"><span class="hljs-built_in">cd</span> /home/pi/.local/lib/python3.<span class="hljs-number">7</span>/site-packages/torchvision/models/
</code></pre>
If you don’t mobilenetv2 or mobilenetv3 we need to manually copy it over. You can use nano <a href="http://mobilenetv2.py">mobilenetv2.py</a> and <a href="http://mobilenetv3.py">mobilenetv3.py</a> to copy the following:<br>
– <a href="http://mobilenetv2.py">mobilenetv2.py</a>:<pre><code class="has-line-data" data-line-start="265" data-line-end="483" class="language-sh">import torch
from torch import nn
from torch import Tensor
from .utils import load_state_dict_from_url
from typing import Callable, Any, Optional, List


__all__ = [<span class="hljs-string">'MobileNetV2'</span>, <span class="hljs-string">'mobilenet_v2'</span>]


model_urls = {
    <span class="hljs-string">'mobilenet_v2'</span>: <span class="hljs-string">'https://download.pytorch.org/models/mobilenet_v2-b0353104.pth'</span>,
}


def _make_divisible(v: <span class="hljs-built_in">float</span>, divisor: int, min_value: Optional[int] = None) -&gt; int:
    <span class="hljs-string">""</span><span class="hljs-string">"
    This function is taken from the original tf repo.
    It ensures that all layers have a channel number that is divisible by 8
    It can be seen here:
    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py
    "</span><span class="hljs-string">""</span>
    <span class="hljs-keyword">if</span> min_value is None:
        min_value = divisor
    new_v = max(min_value, int(v + divisor / <span class="hljs-number">2</span>) // divisor * divisor)
    <span class="hljs-comment"># Make sure that round down does not go down by more than 10%.</span>
    <span class="hljs-keyword">if</span> new_v &lt; <span class="hljs-number">0.9</span> * v:
        new_v += divisor
    <span class="hljs-built_in">return</span> new_v


class ConvBNActivation(nn.Sequential):
    def __init__(
        self,
        <span class="hljs-keyword">in</span>_planes: int,
        out_planes: int,
        kernel_size: int = <span class="hljs-number">3</span>,
        stride: int = <span class="hljs-number">1</span>,
        groups: int = <span class="hljs-number">1</span>,
        norm_layer: Optional[Callable[..., nn.Module]] = None,
        activation_layer: Optional[Callable[..., nn.Module]] = None,
        dilation: int = <span class="hljs-number">1</span>,
    ) -&gt; None:
        padding = (kernel_size - <span class="hljs-number">1</span>) // <span class="hljs-number">2</span> * dilation
        <span class="hljs-keyword">if</span> norm_layer is None:
            norm_layer = nn.BatchNorm2d
        <span class="hljs-keyword">if</span> activation_layer is None:
            activation_layer = nn.ReLU6
        super().__init__(
            nn.Conv2d(<span class="hljs-keyword">in</span>_planes, out_planes, kernel_size, stride, padding, dilation=dilation, groups=groups,
                      bias=False),
            norm_layer(out_planes),
            activation_layer(inplace=True)
        )
        self.out_channels = out_planes


<span class="hljs-comment"># necessary for backwards compatibility</span>
ConvBNReLU = ConvBNActivation


class InvertedResidual(nn.Module):
    def __init__(
        self,
        inp: int,
        oup: int,
        stride: int,
        expand_ratio: int,
        norm_layer: Optional[Callable[..., nn.Module]] = None
    ) -&gt; None:
        super(InvertedResidual, self).__init__()
        self.stride = stride
        assert stride <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]

        <span class="hljs-keyword">if</span> norm_layer is None:
            norm_layer = nn.BatchNorm2d

        hidden_dim = int(round(inp * expand_ratio))
        self.use_res_connect = self.stride == <span class="hljs-number">1</span> and inp == oup

        layers: List[nn.Module] = []
        <span class="hljs-keyword">if</span> expand_ratio != <span class="hljs-number">1</span>:
            <span class="hljs-comment"># pw</span>
            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=<span class="hljs-number">1</span>, norm_layer=norm_layer))
        layers.extend([
            <span class="hljs-comment"># dw</span>
            ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim, norm_layer=norm_layer),
            <span class="hljs-comment"># pw-linear</span>
            nn.Conv2d(hidden_dim, oup, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=False),
            norm_layer(oup),
        ])
        self.conv = nn.Sequential(*layers)
        self.out_channels = oup
        self._is_cn = stride &gt; <span class="hljs-number">1</span>

    def forward(self, x: Tensor) -&gt; Tensor:
        <span class="hljs-keyword">if</span> self.use_res_connect:
            <span class="hljs-built_in">return</span> x + self.conv(x)
        <span class="hljs-keyword">else</span>:
            <span class="hljs-built_in">return</span> self.conv(x)


class MobileNetV2(nn.Module):
    def __init__(
        self,
        num_classes: int = <span class="hljs-number">1000</span>,
        width_mult: <span class="hljs-built_in">float</span> = <span class="hljs-number">1.0</span>,
        inverted_residual_setting: Optional[List[List[int]]] = None,
        round_nearest: int = <span class="hljs-number">8</span>,
        block: Optional[Callable[..., nn.Module]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None
    ) -&gt; None:
        <span class="hljs-string">""</span><span class="hljs-string">"
        MobileNet V2 main class

        Args:
            num_classes (int): Number of classes
            width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount
            inverted_residual_setting: Network structure
            round_nearest (int): Round the number of channels in each layer to be a multiple of this number
            Set to 1 to turn off rounding
            block: Module specifying inverted residual building block for mobilenet
            norm_layer: Module specifying the normalization layer to use

        "</span><span class="hljs-string">""</span>
        super(MobileNetV2, self).__init__()

        <span class="hljs-keyword">if</span> block is None:
            block = InvertedResidual

        <span class="hljs-keyword">if</span> norm_layer is None:
            norm_layer = nn.BatchNorm2d

        input_channel = <span class="hljs-number">32</span>
        last_channel = <span class="hljs-number">1280</span>

        <span class="hljs-keyword">if</span> inverted_residual_setting is None:
            inverted_residual_setting = [
                <span class="hljs-comment"># t, c, n, s</span>
                [<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
                [<span class="hljs-number">6</span>, <span class="hljs-number">24</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>],
                [<span class="hljs-number">6</span>, <span class="hljs-number">32</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>],
                [<span class="hljs-number">6</span>, <span class="hljs-number">64</span>, <span class="hljs-number">4</span>, <span class="hljs-number">2</span>],
                [<span class="hljs-number">6</span>, <span class="hljs-number">96</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],
                [<span class="hljs-number">6</span>, <span class="hljs-number">160</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>],
                [<span class="hljs-number">6</span>, <span class="hljs-number">320</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
            ]

        <span class="hljs-comment"># only check the first element, assuming user knows t,c,n,s are required</span>
        <span class="hljs-keyword">if</span> len(inverted_residual_setting) == <span class="hljs-number">0</span> or len(inverted_residual_setting[<span class="hljs-number">0</span>]) != <span class="hljs-number">4</span>:
            raise ValueError(<span class="hljs-string">"inverted_residual_setting should be non-empty "</span>
                             <span class="hljs-string">"or a 4-element list, got {}"</span>.format(inverted_residual_setting))

        <span class="hljs-comment"># building first layer</span>
        input_channel = _make_divisible(input_channel * width_mult, round_nearest)
        self.last_channel = _make_divisible(last_channel * max(<span class="hljs-number">1.0</span>, width_mult), round_nearest)
        features: List[nn.Module] = [ConvBNReLU(<span class="hljs-number">3</span>, input_channel, stride=<span class="hljs-number">2</span>, norm_layer=norm_layer)]
        <span class="hljs-comment"># building inverted residual blocks</span>
        <span class="hljs-keyword">for</span> t, c, n, s <span class="hljs-keyword">in</span> inverted_residual_setting:
            output_channel = _make_divisible(c * width_mult, round_nearest)
            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):
                stride = s <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span>
                features.append(block(input_channel, output_channel, stride, expand_ratio=t, norm_layer=norm_layer))
                input_channel = output_channel
        <span class="hljs-comment"># building last several layers</span>
        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=<span class="hljs-number">1</span>, norm_layer=norm_layer))
        <span class="hljs-comment"># make it nn.Sequential</span>
        self.features = nn.Sequential(*features)

        <span class="hljs-comment"># building classifier</span>
        self.classifier = nn.Sequential(
            nn.Dropout(<span class="hljs-number">0.2</span>),
            nn.Linear(self.last_channel, num_classes),
        )

        <span class="hljs-comment"># weight initialization</span>
        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.modules():
            <span class="hljs-keyword">if</span> isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">'fan_out'</span>)
                <span class="hljs-keyword">if</span> m.bias is not None:
                    nn.init.zeros_(m.bias)
            <span class="hljs-keyword">elif</span> isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)
            <span class="hljs-keyword">elif</span> isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, <span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>)
                nn.init.zeros_(m.bias)

    def _forward_impl(self, x: Tensor) -&gt; Tensor:
        <span class="hljs-comment"># This exists since TorchScript doesn't support inheritance, so the superclass method</span>
        <span class="hljs-comment"># (this one) needs to have a name other than `forward` that can be accessed in a subclass</span>
        x = self.features(x)
        <span class="hljs-comment"># Cannot use "squeeze" as batch-size can be 1</span>
        x = nn.functional.adaptive_avg_pool2d(x, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))
        x = torch.flatten(x, <span class="hljs-number">1</span>)
        x = self.classifier(x)
        <span class="hljs-built_in">return</span> x

    def forward(self, x: Tensor) -&gt; Tensor:
        <span class="hljs-built_in">return</span> self._forward_impl(x)


def mobilenet_v2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; MobileNetV2:
    <span class="hljs-string">""</span><span class="hljs-string">"
    Constructs a MobileNetV2 architecture from
    `"</span>MobileNetV2: Inverted Residuals and Linear Bottlenecks<span class="hljs-string">" &lt;https://arxiv.org/abs/1801.04381&gt;`_.

    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
        progress (bool): If True, displays a progress bar of the download to stderr
    "</span><span class="hljs-string">""</span>
    model = MobileNetV2(**kwargs)
    <span class="hljs-keyword">if</span> pretrained:
        state_dict = load_state_dict_from_url(model_urls[<span class="hljs-string">'mobilenet_v2'</span>],
                                              progress=progress)
        model.load_state_dict(state_dict)
    <span class="hljs-built_in">return</span> model
</code></pre>
– <a href="http://mobilenetv3.py">mobilenetv3.py</a>:<pre><code class="has-line-data" data-line-start="485" data-line-end="768" class="language-sh">import torch

from functools import partial
from torch import nn, Tensor
from torch.nn import functional as F
from typing import Any, Callable, Dict, List, Optional, Sequence

from torchvision.models.utils import load_state_dict_from_url
from torchvision.models.mobilenetv2 import _make_divisible, ConvBNActivation


__all__ = [<span class="hljs-string">"MobileNetV3"</span>, <span class="hljs-string">"mobilenet_v3_large"</span>, <span class="hljs-string">"mobilenet_v3_small"</span>]


model_urls = {
    <span class="hljs-string">"mobilenet_v3_large"</span>: <span class="hljs-string">"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth"</span>,
    <span class="hljs-string">"mobilenet_v3_small"</span>: <span class="hljs-string">"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth"</span>,
}


class SqueezeExcitation(nn.Module):
    <span class="hljs-comment"># Implemented as described at Figure 4 of the MobileNetV3 paper</span>
    def __init__(self, input_channels: int, squeeze_factor: int = <span class="hljs-number">4</span>):
        super().__init__()
        squeeze_channels = _make_divisible(input_channels // squeeze_factor, <span class="hljs-number">8</span>)
        self.fc1 = nn.Conv2d(input_channels, squeeze_channels, <span class="hljs-number">1</span>)
        self.relu = nn.ReLU(inplace=True)
        self.fc2 = nn.Conv2d(squeeze_channels, input_channels, <span class="hljs-number">1</span>)

    def _scale(self, input: Tensor, inplace: bool) -&gt; Tensor:
        scale = F.adaptive_avg_pool2d(input, <span class="hljs-number">1</span>)
        scale = self.fc1(scale)
        scale = self.relu(scale)
        scale = self.fc2(scale)
        <span class="hljs-built_in">return</span> F.hardsigmoid(scale, inplace=inplace)

    def forward(self, input: Tensor) -&gt; Tensor:
        scale = self._scale(input, True)
        <span class="hljs-built_in">return</span> scale * input


class InvertedResidualConfig:
    <span class="hljs-comment"># Stores information listed at Tables 1 and 2 of the MobileNetV3 paper</span>
    def __init__(self, input_channels: int, kernel: int, expanded_channels: int, out_channels: int, use_se: bool,
                 activation: str, stride: int, dilation: int, width_mult: <span class="hljs-built_in">float</span>):
        self.input_channels = self.adjust_channels(input_channels, width_mult)
        self.kernel = kernel
        self.expanded_channels = self.adjust_channels(expanded_channels, width_mult)
        self.out_channels = self.adjust_channels(out_channels, width_mult)
        self.use_se = use_se
        self.use_hs = activation == <span class="hljs-string">"HS"</span>
        self.stride = stride
        self.dilation = dilation

    @staticmethod
    def adjust_channels(channels: int, width_mult: <span class="hljs-built_in">float</span>):
        <span class="hljs-built_in">return</span> _make_divisible(channels * width_mult, <span class="hljs-number">8</span>)


class InvertedResidual(nn.Module):
    <span class="hljs-comment"># Implemented as described at section 5 of MobileNetV3 paper</span>
    def __init__(self, cnf: InvertedResidualConfig, norm_layer: Callable[..., nn.Module],
                 se_layer: Callable[..., nn.Module] = SqueezeExcitation):
        super().__init__()
        <span class="hljs-keyword">if</span> not (<span class="hljs-number">1</span> &lt;= cnf.stride &lt;= <span class="hljs-number">2</span>):
            raise ValueError(<span class="hljs-string">'illegal stride value'</span>)

        self.use_res_connect = cnf.stride == <span class="hljs-number">1</span> and cnf.input_channels == cnf.out_channels

        layers: List[nn.Module] = []
        activation_layer = nn.Hardswish <span class="hljs-keyword">if</span> cnf.use_hs <span class="hljs-keyword">else</span> nn.ReLU

        <span class="hljs-comment"># expand</span>
        <span class="hljs-keyword">if</span> cnf.expanded_channels != cnf.input_channels:
            layers.append(ConvBNActivation(cnf.input_channels, cnf.expanded_channels, kernel_size=<span class="hljs-number">1</span>,
                                           norm_layer=norm_layer, activation_layer=activation_layer))

        <span class="hljs-comment"># depthwise</span>
        stride = <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> cnf.dilation &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> cnf.stride
        layers.append(ConvBNActivation(cnf.expanded_channels, cnf.expanded_channels, kernel_size=cnf.kernel,
                                       stride=stride, dilation=cnf.dilation, groups=cnf.expanded_channels,
                                       norm_layer=norm_layer, activation_layer=activation_layer))
        <span class="hljs-keyword">if</span> cnf.use_se:
            layers.append(se_layer(cnf.expanded_channels))

        <span class="hljs-comment"># project</span>
        layers.append(ConvBNActivation(cnf.expanded_channels, cnf.out_channels, kernel_size=<span class="hljs-number">1</span>, norm_layer=norm_layer,
                                       activation_layer=nn.Identity))

        self.block = nn.Sequential(*layers)
        self.out_channels = cnf.out_channels
        self._is_cn = cnf.stride &gt; <span class="hljs-number">1</span>

    def forward(self, input: Tensor) -&gt; Tensor:
        result = self.block(input)
        <span class="hljs-keyword">if</span> self.use_res_connect:
            result += input
        <span class="hljs-built_in">return</span> result


class MobileNetV3(nn.Module):

    def __init__(
            self,
            inverted_residual_setting: List[InvertedResidualConfig],
            last_channel: int,
            num_classes: int = <span class="hljs-number">1000</span>,
            block: Optional[Callable[..., nn.Module]] = None,
            norm_layer: Optional[Callable[..., nn.Module]] = None,
            **kwargs: Any
    ) -&gt; None:
        <span class="hljs-string">""</span><span class="hljs-string">"
        MobileNet V3 main class

        Args:
            inverted_residual_setting (List[InvertedResidualConfig]): Network structure
            last_channel (int): The number of channels on the penultimate layer
            num_classes (int): Number of classes
            block (Optional[Callable[..., nn.Module]]): Module specifying inverted residual building block for mobilenet
            norm_layer (Optional[Callable[..., nn.Module]]): Module specifying the normalization layer to use
        "</span><span class="hljs-string">""</span>
        super().__init__()

        <span class="hljs-keyword">if</span> not inverted_residual_setting:
            raise ValueError(<span class="hljs-string">"The inverted_residual_setting should not be empty"</span>)
        <span class="hljs-keyword">elif</span> not (isinstance(inverted_residual_setting, Sequence) and
                  all([isinstance(s, InvertedResidualConfig) <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> inverted_residual_setting])):
            raise TypeError(<span class="hljs-string">"The inverted_residual_setting should be List[InvertedResidualConfig]"</span>)

        <span class="hljs-keyword">if</span> block is None:
            block = InvertedResidual

        <span class="hljs-keyword">if</span> norm_layer is None:
            norm_layer = partial(nn.BatchNorm2d, eps=<span class="hljs-number">0.001</span>, momentum=<span class="hljs-number">0.01</span>)

        layers: List[nn.Module] = []

        <span class="hljs-comment"># building first layer</span>
        firstconv_output_channels = inverted_residual_setting[<span class="hljs-number">0</span>].input_channels
        layers.append(ConvBNActivation(<span class="hljs-number">3</span>, firstconv_output_channels, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, norm_layer=norm_layer,
                                       activation_layer=nn.Hardswish))

        <span class="hljs-comment"># building inverted residual blocks</span>
        <span class="hljs-keyword">for</span> cnf <span class="hljs-keyword">in</span> inverted_residual_setting:
            layers.append(block(cnf, norm_layer))

        <span class="hljs-comment"># building last several layers</span>
        lastconv_input_channels = inverted_residual_setting[-<span class="hljs-number">1</span>].out_channels
        lastconv_output_channels = <span class="hljs-number">6</span> * lastconv_input_channels
        layers.append(ConvBNActivation(lastconv_input_channels, lastconv_output_channels, kernel_size=<span class="hljs-number">1</span>,
                                       norm_layer=norm_layer, activation_layer=nn.Hardswish))

        self.features = nn.Sequential(*layers)
        self.avgpool = nn.AdaptiveAvgPool2d(<span class="hljs-number">1</span>)
        self.classifier = nn.Sequential(
            nn.Linear(lastconv_output_channels, last_channel),
            nn.Hardswish(inplace=True),
            nn.Dropout(p=<span class="hljs-number">0.2</span>, inplace=True),
            nn.Linear(last_channel, num_classes),
        )

        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.modules():
            <span class="hljs-keyword">if</span> isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">'fan_out'</span>)
                <span class="hljs-keyword">if</span> m.bias is not None:
                    nn.init.zeros_(m.bias)
            <span class="hljs-keyword">elif</span> isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)
            <span class="hljs-keyword">elif</span> isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, <span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>)
                nn.init.zeros_(m.bias)

    def _forward_impl(self, x: Tensor) -&gt; Tensor:
        x = self.features(x)

        x = self.avgpool(x)
        x = torch.flatten(x, <span class="hljs-number">1</span>)

        x = self.classifier(x)

        <span class="hljs-built_in">return</span> x

    def forward(self, x: Tensor) -&gt; Tensor:
        <span class="hljs-built_in">return</span> self._forward_impl(x)


def _mobilenet_v3_conf(arch: str, width_mult: <span class="hljs-built_in">float</span> = <span class="hljs-number">1.0</span>, reduced_tail: bool = False, dilated: bool = False,
                       **kwargs: Any):
    reduce_divider = <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> reduced_tail <span class="hljs-keyword">else</span> <span class="hljs-number">1</span>
    dilation = <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> dilated <span class="hljs-keyword">else</span> <span class="hljs-number">1</span>

    bneck_conf = partial(InvertedResidualConfig, width_mult=width_mult)
    adjust_channels = partial(InvertedResidualConfig.adjust_channels, width_mult=width_mult)

    <span class="hljs-keyword">if</span> arch == <span class="hljs-string">"mobilenet_v3_large"</span>:
        inverted_residual_setting = [
            bneck_conf(<span class="hljs-number">16</span>, <span class="hljs-number">3</span>, <span class="hljs-number">16</span>, <span class="hljs-number">16</span>, False, <span class="hljs-string">"RE"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">16</span>, <span class="hljs-number">3</span>, <span class="hljs-number">64</span>, <span class="hljs-number">24</span>, False, <span class="hljs-string">"RE"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>),  <span class="hljs-comment"># C1</span>
            bneck_conf(<span class="hljs-number">24</span>, <span class="hljs-number">3</span>, <span class="hljs-number">72</span>, <span class="hljs-number">24</span>, False, <span class="hljs-string">"RE"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">24</span>, <span class="hljs-number">5</span>, <span class="hljs-number">72</span>, <span class="hljs-number">40</span>, True, <span class="hljs-string">"RE"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>),  <span class="hljs-comment"># C2</span>
            bneck_conf(<span class="hljs-number">40</span>, <span class="hljs-number">5</span>, <span class="hljs-number">120</span>, <span class="hljs-number">40</span>, True, <span class="hljs-string">"RE"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">40</span>, <span class="hljs-number">5</span>, <span class="hljs-number">120</span>, <span class="hljs-number">40</span>, True, <span class="hljs-string">"RE"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">40</span>, <span class="hljs-number">3</span>, <span class="hljs-number">240</span>, <span class="hljs-number">80</span>, False, <span class="hljs-string">"HS"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>),  <span class="hljs-comment"># C3</span>
            bneck_conf(<span class="hljs-number">80</span>, <span class="hljs-number">3</span>, <span class="hljs-number">200</span>, <span class="hljs-number">80</span>, False, <span class="hljs-string">"HS"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">80</span>, <span class="hljs-number">3</span>, <span class="hljs-number">184</span>, <span class="hljs-number">80</span>, False, <span class="hljs-string">"HS"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">80</span>, <span class="hljs-number">3</span>, <span class="hljs-number">184</span>, <span class="hljs-number">80</span>, False, <span class="hljs-string">"HS"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">80</span>, <span class="hljs-number">3</span>, <span class="hljs-number">480</span>, <span class="hljs-number">112</span>, True, <span class="hljs-string">"HS"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">112</span>, <span class="hljs-number">3</span>, <span class="hljs-number">672</span>, <span class="hljs-number">112</span>, True, <span class="hljs-string">"HS"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">112</span>, <span class="hljs-number">5</span>, <span class="hljs-number">672</span>, <span class="hljs-number">160</span> // reduce_divider, True, <span class="hljs-string">"HS"</span>, <span class="hljs-number">2</span>, dilation),  <span class="hljs-comment"># C4</span>
            bneck_conf(<span class="hljs-number">160</span> // reduce_divider, <span class="hljs-number">5</span>, <span class="hljs-number">960</span> // reduce_divider, <span class="hljs-number">160</span> // reduce_divider, True, <span class="hljs-string">"HS"</span>, <span class="hljs-number">1</span>, dilation),
            bneck_conf(<span class="hljs-number">160</span> // reduce_divider, <span class="hljs-number">5</span>, <span class="hljs-number">960</span> // reduce_divider, <span class="hljs-number">160</span> // reduce_divider, True, <span class="hljs-string">"HS"</span>, <span class="hljs-number">1</span>, dilation),
        ]
        last_channel = adjust_channels(<span class="hljs-number">1280</span> // reduce_divider)  <span class="hljs-comment"># C5</span>
    <span class="hljs-keyword">elif</span> arch == <span class="hljs-string">"mobilenet_v3_small"</span>:
        inverted_residual_setting = [
            bneck_conf(<span class="hljs-number">16</span>, <span class="hljs-number">3</span>, <span class="hljs-number">16</span>, <span class="hljs-number">16</span>, True, <span class="hljs-string">"RE"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>),  <span class="hljs-comment"># C1</span>
            bneck_conf(<span class="hljs-number">16</span>, <span class="hljs-number">3</span>, <span class="hljs-number">72</span>, <span class="hljs-number">24</span>, False, <span class="hljs-string">"RE"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>),  <span class="hljs-comment"># C2</span>
            bneck_conf(<span class="hljs-number">24</span>, <span class="hljs-number">3</span>, <span class="hljs-number">88</span>, <span class="hljs-number">24</span>, False, <span class="hljs-string">"RE"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">24</span>, <span class="hljs-number">5</span>, <span class="hljs-number">96</span>, <span class="hljs-number">40</span>, True, <span class="hljs-string">"HS"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>),  <span class="hljs-comment"># C3</span>
            bneck_conf(<span class="hljs-number">40</span>, <span class="hljs-number">5</span>, <span class="hljs-number">240</span>, <span class="hljs-number">40</span>, True, <span class="hljs-string">"HS"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">40</span>, <span class="hljs-number">5</span>, <span class="hljs-number">240</span>, <span class="hljs-number">40</span>, True, <span class="hljs-string">"HS"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">40</span>, <span class="hljs-number">5</span>, <span class="hljs-number">120</span>, <span class="hljs-number">48</span>, True, <span class="hljs-string">"HS"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">48</span>, <span class="hljs-number">5</span>, <span class="hljs-number">144</span>, <span class="hljs-number">48</span>, True, <span class="hljs-string">"HS"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),
            bneck_conf(<span class="hljs-number">48</span>, <span class="hljs-number">5</span>, <span class="hljs-number">288</span>, <span class="hljs-number">96</span> // reduce_divider, True, <span class="hljs-string">"HS"</span>, <span class="hljs-number">2</span>, dilation),  <span class="hljs-comment"># C4</span>
            bneck_conf(<span class="hljs-number">96</span> // reduce_divider, <span class="hljs-number">5</span>, <span class="hljs-number">576</span> // reduce_divider, <span class="hljs-number">96</span> // reduce_divider, True, <span class="hljs-string">"HS"</span>, <span class="hljs-number">1</span>, dilation),
            bneck_conf(<span class="hljs-number">96</span> // reduce_divider, <span class="hljs-number">5</span>, <span class="hljs-number">576</span> // reduce_divider, <span class="hljs-number">96</span> // reduce_divider, True, <span class="hljs-string">"HS"</span>, <span class="hljs-number">1</span>, dilation),
        ]
        last_channel = adjust_channels(<span class="hljs-number">1024</span> // reduce_divider)  <span class="hljs-comment"># C5</span>
    <span class="hljs-keyword">else</span>:
        raise ValueError(<span class="hljs-string">"Unsupported model type {}"</span>.format(arch))

    <span class="hljs-built_in">return</span> inverted_residual_setting, last_channel


def _mobilenet_v3_model(
    arch: str,
    inverted_residual_setting: List[InvertedResidualConfig],
    last_channel: int,
    pretrained: bool,
    progress: bool,
    **kwargs: Any
):
    model = MobileNetV3(inverted_residual_setting, last_channel, **kwargs)
    <span class="hljs-keyword">if</span> pretrained:
        <span class="hljs-keyword">if</span> model_urls.get(arch, None) is None:
            raise ValueError(<span class="hljs-string">"No checkpoint is available for model type {}"</span>.format(arch))
        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)
        model.load_state_dict(state_dict)
    <span class="hljs-built_in">return</span> model



def mobilenet_v3_large(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; MobileNetV3:
    <span class="hljs-string">""</span><span class="hljs-string">"
    Constructs a large MobileNetV3 architecture from
    `"</span>Searching <span class="hljs-keyword">for</span> MobileNetV3<span class="hljs-string">" &lt;https://arxiv.org/abs/1905.02244&gt;`_.

    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
        progress (bool): If True, displays a progress bar of the download to stderr
    "</span><span class="hljs-string">""</span>
    arch = <span class="hljs-string">"mobilenet_v3_large"</span>
    inverted_residual_setting, last_channel = _mobilenet_v3_conf(arch, **kwargs)
    <span class="hljs-built_in">return</span> _mobilenet_v3_model(arch, inverted_residual_setting, last_channel, pretrained, progress, **kwargs)




def mobilenet_v3_small(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; MobileNetV3:
    <span class="hljs-string">""</span><span class="hljs-string">"
    Constructs a small MobileNetV3 architecture from
    `"</span>Searching <span class="hljs-keyword">for</span> MobileNetV3<span class="hljs-string">" &lt;https://arxiv.org/abs/1905.02244&gt;`_.

    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
        progress (bool): If True, displays a progress bar of the download to stderr
    "</span><span class="hljs-string">""</span>
    arch = <span class="hljs-string">"mobilenet_v3_small"</span>
    inverted_residual_setting, last_channel = _mobilenet_v3_conf(arch, **kwargs)
    <span class="hljs-built_in">return</span> _mobilenet_v3_model(arch, inverted_residual_setting, last_channel, pretrained, progress, **kwargs)

</code></pre>
– Let’s <a href="https://drive.google.com/drive/folders/1DuSfiI60ORgVqJtft2Jv6lF9qZgUL7r0?usp=sharing">download an example of an artifact</a> and transfer from local to the Raspberrypi<pre><code class="has-line-data" data-line-start="770" data-line-end="772" class="language-sh">scp -r &lt;LOCAL_DIR&gt;/MobileNetV3_100 <a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="83f3eac3f1e2f0f3e1e6f1f1faf3eaadefece0e2ef">[email&#160;protected]</a>:/home/pi/artifacts/
</code></pre>
– Finally, we can run our flask server by:<pre><code class="has-line-data" data-line-start="774" data-line-end="776" class="language-sh">python3 flask_server.py
</code></pre>
– And make a GET call from Postman on the inference endpoint:<br>
<code>&lt;RPI_IP&gt;/api/inference/</code><br>
If successful, there response will look like:<pre><code class="has-line-data" data-line-start="782" data-line-end="786" class="language-sh">{
<span class="hljs-string">"image"</span>: <span class="hljs-string">"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"</span>,
<span class="hljs-string">"predicted"</span>: <span class="hljs-string">"empty"</span>,
<span class="hljs-string">"timestamp"</span>: <span class="hljs-string">"Mon, 04 Oct 2021 23:25:05 GMT"</span>
</code></pre>
</li>
</ul>
<p class="has-line-data" data-line-start="786" data-line-end="787">}</p>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script></body></html>